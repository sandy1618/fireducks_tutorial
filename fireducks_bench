{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e774a4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T04:47:56.856932Z",
     "iopub.status.busy": "2024-08-05T04:47:56.856493Z",
     "iopub.status.idle": "2024-08-05T04:48:25.434233Z",
     "shell.execute_reply": "2024-08-05T04:48:25.432623Z"
    },
    "papermill": {
     "duration": 28.590493,
     "end_time": "2024-08-05T04:48:25.437526",
     "exception": false,
     "start_time": "2024-08-05T04:47:56.847033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\r\n",
      "Collecting fireducks\r\n",
      "  Downloading fireducks-0.13.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\r\n",
      "Requirement already satisfied: polars in /opt/conda/lib/python3.10/site-packages (1.1.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\r\n",
      "Collecting modin[dask]\r\n",
      "  Downloading modin-0.31.0-py3-none-any.whl.metadata (17 kB)\r\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\r\n",
      "Collecting firefw==0.13.0 (from fireducks)\r\n",
      "  Downloading firefw-0.13.0-py3-none-any.whl.metadata (768 bytes)\r\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from fireducks) (0.58.1)\r\n",
      "Collecting pyarrow<17.1,>=17.0 (from fireducks)\r\n",
      "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\r\n",
      "Requirement already satisfied: packaging>=21.0 in /opt/conda/lib/python3.10/site-packages (from modin[dask]) (21.3)\r\n",
      "Requirement already satisfied: fsspec>=2022.11.0 in /opt/conda/lib/python3.10/site-packages (from modin[dask]) (2024.5.0)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from modin[dask]) (5.9.3)\r\n",
      "Requirement already satisfied: dask>=2.22.0 in /opt/conda/lib/python3.10/site-packages (from modin[dask]) (2024.7.0)\r\n",
      "Collecting distributed>=2.22.0 (from modin[dask])\r\n",
      "  Downloading distributed-2024.7.1-py3-none-any.whl.metadata (3.4 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\r\n",
      "Requirement already satisfied: click>=8.1 in /opt/conda/lib/python3.10/site-packages (from dask>=2.22.0->modin[dask]) (8.1.7)\r\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from dask>=2.22.0->modin[dask]) (2.2.1)\r\n",
      "Requirement already satisfied: partd>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from dask>=2.22.0->modin[dask]) (1.4.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from dask>=2.22.0->modin[dask]) (6.0.1)\r\n",
      "Requirement already satisfied: toolz>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from dask>=2.22.0->modin[dask]) (0.12.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /opt/conda/lib/python3.10/site-packages (from dask>=2.22.0->modin[dask]) (6.11.0)\r\n",
      "Collecting dask>=2.22.0 (from modin[dask])\r\n",
      "  Downloading dask-2024.7.1-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.22.0->modin[dask]) (3.1.2)\r\n",
      "Requirement already satisfied: locket>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.22.0->modin[dask]) (1.0.0)\r\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.22.0->modin[dask]) (1.0.7)\r\n",
      "Collecting sortedcontainers>=2.0.5 (from distributed>=2.22.0->modin[dask])\r\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting tblib>=1.6.0 (from distributed>=2.22.0->modin[dask])\r\n",
      "  Downloading tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\r\n",
      "Requirement already satisfied: tornado>=6.0.4 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.22.0->modin[dask]) (6.3.3)\r\n",
      "Requirement already satisfied: urllib3>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from distributed>=2.22.0->modin[dask]) (1.26.18)\r\n",
      "Collecting zict>=3.0.0 (from distributed>=2.22.0->modin[dask])\r\n",
      "  Downloading zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->fireducks) (0.41.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask>=2.22.0->modin[dask]) (3.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.10.3->distributed>=2.22.0->modin[dask]) (2.1.3)\r\n",
      "Downloading fireducks-0.13.0-cp310-cp310-manylinux_2_28_x86_64.whl (6.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading firefw-0.13.0-py3-none-any.whl (12 kB)\r\n",
      "Downloading distributed-2024.7.1-py3-none-any.whl (1.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading dask-2024.7.1-py3-none-any.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading modin-0.31.0-py3-none-any.whl (1.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\r\n",
      "Downloading tblib-3.0.0-py3-none-any.whl (12 kB)\r\n",
      "Downloading zict-3.0.0-py2.py3-none-any.whl (43 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: sortedcontainers, zict, tblib, pyarrow, firefw, dask, modin, fireducks, distributed\r\n",
      "  Attempting uninstall: pyarrow\r\n",
      "    Found existing installation: pyarrow 16.1.0\r\n",
      "    Uninstalling pyarrow-16.1.0:\r\n",
      "      Successfully uninstalled pyarrow-16.1.0\r\n",
      "  Attempting uninstall: dask\r\n",
      "    Found existing installation: dask 2024.7.0\r\n",
      "    Uninstalling dask-2024.7.0:\r\n",
      "      Successfully uninstalled dask-2024.7.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 17.0.0 which is incompatible.\r\n",
      "beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.3 which is incompatible.\r\n",
      "dask-expr 1.1.7 requires dask==2024.7.0, but you have dask 2024.7.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed dask-2024.7.1 distributed-2024.7.1 fireducks-0.13.0 firefw-0.13.0 modin-0.31.0 pyarrow-17.0.0 sortedcontainers-2.4.0 tblib-3.0.0 zict-3.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas fireducks modin[dask] polars matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ebe6dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T04:48:25.466383Z",
     "iopub.status.busy": "2024-08-05T04:48:25.465752Z",
     "iopub.status.idle": "2024-08-05T04:48:26.643400Z",
     "shell.execute_reply": "2024-08-05T04:48:26.641831Z"
    },
    "papermill": {
     "duration": 1.1954,
     "end_time": "2024-08-05T04:48:26.646643",
     "exception": false,
     "start_time": "2024-08-05T04:48:25.451243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:                         x86_64\r\n",
      "CPU op-mode(s):                       32-bit, 64-bit\r\n",
      "Byte Order:                           Little Endian\r\n",
      "Address sizes:                        46 bits physical, 48 bits virtual\r\n",
      "CPU(s):                               4\r\n",
      "On-line CPU(s) list:                  0-3\r\n",
      "Thread(s) per core:                   2\r\n",
      "Core(s) per socket:                   2\r\n",
      "Socket(s):                            1\r\n",
      "NUMA node(s):                         1\r\n",
      "Vendor ID:                            GenuineIntel\r\n",
      "CPU family:                           6\r\n",
      "Model:                                79\r\n",
      "Model name:                           Intel(R) Xeon(R) CPU @ 2.20GHz\r\n",
      "Stepping:                             0\r\n",
      "CPU MHz:                              2199.998\r\n",
      "BogoMIPS:                             4399.99\r\n",
      "Hypervisor vendor:                    KVM\r\n",
      "Virtualization type:                  full\r\n",
      "L1d cache:                            64 KiB\r\n",
      "L1i cache:                            64 KiB\r\n",
      "L2 cache:                             512 KiB\r\n",
      "L3 cache:                             55 MiB\r\n",
      "NUMA node0 CPU(s):                    0-3\r\n",
      "Vulnerability Gather data sampling:   Not affected\r\n",
      "Vulnerability Itlb multihit:          Not affected\r\n",
      "Vulnerability L1tf:                   Mitigation; PTE Inversion\r\n",
      "Vulnerability Mds:                    Mitigation; Clear CPU buffers; SMT Host st\r\n",
      "                                      ate unknown\r\n",
      "Vulnerability Meltdown:               Mitigation; PTI\r\n",
      "Vulnerability Mmio stale data:        Vulnerable: Clear CPU buffers attempted, n\r\n",
      "                                      o microcode; SMT Host state unknown\r\n",
      "Vulnerability Reg file data sampling: Not affected\r\n",
      "Vulnerability Retbleed:               Mitigation; IBRS\r\n",
      "Vulnerability Spec rstack overflow:   Not affected\r\n",
      "Vulnerability Spec store bypass:      Mitigation; Speculative Store Bypass disab\r\n",
      "                                      led via prctl and seccomp\r\n",
      "Vulnerability Spectre v1:             Mitigation; usercopy/swapgs barriers and _\r\n",
      "                                      _user pointer sanitization\r\n",
      "Vulnerability Spectre v2:             Mitigation; IBRS; IBPB conditional; STIBP \r\n",
      "                                      conditional; RSB filling; PBRSB-eIBRS Not \r\n",
      "                                      affected; BHI SW loop, KVM SW loop\r\n",
      "Vulnerability Srbds:                  Not affected\r\n",
      "Vulnerability Tsx async abort:        Mitigation; Clear CPU buffers; SMT Host st\r\n",
      "                                      ate unknown\r\n",
      "Flags:                                fpu vme de pse tsc msr pae mce cx8 apic se\r\n",
      "                                      p mtrr pge mca cmov pat pse36 clflush mmx \r\n",
      "                                      fxsr sse sse2 ss ht syscall nx pdpe1gb rdt\r\n",
      "                                      scp lm constant_tsc rep_good nopl xtopolog\r\n",
      "                                      y nonstop_tsc cpuid tsc_known_freq pni pcl\r\n",
      "                                      mulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x\r\n",
      "                                      2apic movbe popcnt aes xsave avx f16c rdra\r\n",
      "                                      nd hypervisor lahf_lm abm 3dnowprefetch in\r\n",
      "                                      vpcid_single pti ssbd ibrs ibpb stibp fsgs\r\n",
      "                                      base tsc_adjust bmi1 hle avx2 smep bmi2 er\r\n",
      "                                      ms invpcid rtm rdseed adx smap xsaveopt ar\r\n",
      "                                      at md_clear arch_capabilities\r\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82af4493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T04:48:26.673942Z",
     "iopub.status.busy": "2024-08-05T04:48:26.673432Z",
     "iopub.status.idle": "2024-08-05T04:48:26.680429Z",
     "shell.execute_reply": "2024-08-05T04:48:26.679237Z"
    },
    "papermill": {
     "duration": 0.024095,
     "end_time": "2024-08-05T04:48:26.682970",
     "exception": false,
     "start_time": "2024-08-05T04:48:26.658875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load_ext fireducks.ipyext\n",
    "\n",
    "import os\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['FIREDUCKS_FLAGS'] = '--benchmark-mode'\n",
    "os.environ['FIREDUCKS_FLAGS'] = \"-Wfallback\"\n",
    "os.environ['FIREDUCKS_FLAGS'] = \"--trace=3\"\n",
    "\n",
    "\n",
    "# Verify that the environment variable is set\n",
    "# print(os.getenv('FIREDUCKS_FLAGS'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0839b6b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-05T04:48:26.709180Z",
     "iopub.status.busy": "2024-08-05T04:48:26.708662Z",
     "iopub.status.idle": "2024-08-05T04:48:28.199173Z",
     "shell.execute_reply": "2024-08-05T04:48:28.197728Z"
    },
    "papermill": {
     "duration": 1.507041,
     "end_time": "2024-08-05T04:48:28.202035",
     "exception": false,
     "start_time": "2024-08-05T04:48:26.694994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0]\n",
      "pandas: 2.2.2\n",
      "fireducks.pandas: 0.13.0\n",
      "modin.pandas: 0.31.0\n",
      "polars: 1.1.0\n",
      "matplotlib: 3.7.5\n",
      "logging: 0.5.1.2\n",
      "/kaggle/input/zvuk-dataset/zvuk-interactions.parquet\n",
      "/kaggle/input/zvuk-dataset/zvuk-track_artist_embedding.parquet\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import fireducks.pandas as fd_pd\n",
    "import modin.pandas as md_pd\n",
    "import polars as pl\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import logging\n",
    "import sys \n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"fireducks.pandas:\", fd_pd.__version__)\n",
    "print(\"modin.pandas:\", md_pd.__version__)\n",
    "print(\"polars:\", pl.__version__)\n",
    "print(\"matplotlib:\", matplotlib.__version__)\n",
    "print(\"logging:\", logging.__version__)\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43453504",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T04:48:28.228961Z",
     "iopub.status.busy": "2024-08-05T04:48:28.228364Z",
     "iopub.status.idle": "2024-08-05T04:48:28.234360Z",
     "shell.execute_reply": "2024-08-05T04:48:28.233120Z"
    },
    "papermill": {
     "duration": 0.022631,
     "end_time": "2024-08-05T04:48:28.236950",
     "exception": false,
     "start_time": "2024-08-05T04:48:28.214319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# File paths\n",
    "path1 = \"/kaggle/input/zvuk-dataset/zvuk-interactions.parquet\"  # Update to .csv if needed\n",
    "path2 = \"/kaggle/input/zvuk-dataset/zvuk-track_artist_embedding.parquet\"  # Update to .csv if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e5a14",
   "metadata": {
    "papermill": {
     "duration": 0.012067,
     "end_time": "2024-08-05T04:48:28.261127",
     "exception": false,
     "start_time": "2024-08-05T04:48:28.249060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Latest way of benchmarking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c877055",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T04:48:28.287969Z",
     "iopub.status.busy": "2024-08-05T04:48:28.287445Z",
     "iopub.status.idle": "2024-08-05T04:48:28.299062Z",
     "shell.execute_reply": "2024-08-05T04:48:28.297397Z"
    },
    "papermill": {
     "duration": 0.028062,
     "end_time": "2024-08-05T04:48:28.301474",
     "exception": true,
     "start_time": "2024-08-05T04:48:28.273412",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%fireducks.profile` not found.\n"
     ]
    }
   ],
   "source": [
    "%%fireducks.profile\n",
    "\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import fireducks.pandas as fd_pd\n",
    "import modin.pandas as md_pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import logging\n",
    "import numpy as np\n",
    "from distributed import Client, LocalCluster\n",
    "\n",
    "# Initialize Dask client\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "\n",
    "# Set Modin engine to Dask\n",
    "os.environ[\"MODIN_ENGINE\"] = \"dask\"\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define load operations\n",
    "def load_pandas(path):\n",
    "    if path.endswith('.csv'):\n",
    "        return pd.read_csv(path)\n",
    "    elif path.endswith('.parquet'):\n",
    "        return pd.read_parquet(path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "def load_fireducks(path):\n",
    "    if path.endswith('.csv'):\n",
    "        return fd_pd.read_csv(path)\n",
    "    elif path.endswith('.parquet'):\n",
    "        return fd_pd.read_parquet(path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "def load_modin(path):\n",
    "    if path.endswith('.csv'):\n",
    "        return md_pd.read_csv(path)\n",
    "    elif path.endswith('.parquet'):\n",
    "        return md_pd.read_parquet(path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "def load_polars(path):\n",
    "    if path.endswith('.csv'):\n",
    "        return pl.scan_csv(path)\n",
    "    elif path.endswith('.parquet'):\n",
    "        return pl.scan_parquet(path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "# Define clean operations\n",
    "def dropna_pandas(df):\n",
    "    return df.dropna()\n",
    "\n",
    "def dropna_fireducks(df):\n",
    "    return df.dropna()\n",
    "\n",
    "def dropna_modin(df):\n",
    "    return df.dropna()\n",
    "\n",
    "def dropna_polars(df):\n",
    "    return df.drop_nulls()\n",
    "\n",
    "def filter_play_duration_pandas(df):\n",
    "    return df[df['play_duration'] > 0]\n",
    "\n",
    "def filter_play_duration_fireducks(df):\n",
    "    return df[df['play_duration'] > 0]\n",
    "\n",
    "def filter_play_duration_modin(df):\n",
    "    return df[df['play_duration'] > 0]\n",
    "\n",
    "def filter_play_duration_polars(df):\n",
    "    return df.filter(pl.col('play_duration') > 0)\n",
    "\n",
    "# Define data summarization operation (average of play_duration)\n",
    "def avg_pandas(df):\n",
    "    return df['play_duration'].mean()\n",
    "\n",
    "def avg_fireducks(df):\n",
    "    return df['play_duration'].mean()\n",
    "\n",
    "def avg_modin(df):\n",
    "    return df['play_duration'].mean()\n",
    "\n",
    "def avg_polars(df):\n",
    "    return df.select(pl.col('play_duration').mean())\n",
    "\n",
    "\n",
    "\n",
    "# Measure and record results\n",
    "results = {\n",
    "    'Library': [],\n",
    "    'Operation': [],\n",
    "    'Time (seconds)': []\n",
    "}\n",
    "\n",
    "path = path1\n",
    "\n",
    "\n",
    "# Function to time operations\n",
    "def time_operation(df, operation_func, lib, operation_name):\n",
    "    start_time = time.time()\n",
    "#     df = load_func(path)\n",
    "    df=operation_func(df)\n",
    "#     print(df)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    results['Library'].append(lib)\n",
    "    results['Operation'].append(operation_name)\n",
    "    results['Time (seconds)'].append(elapsed_time)\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "# Define operations for each library\n",
    "operations = [\n",
    "    ('Clean Data - Drop NA', dropna_pandas, dropna_fireducks, dropna_modin, dropna_polars),\n",
    "    ('Clean Data - Filter Play Duration', filter_play_duration_pandas, filter_play_duration_fireducks, filter_play_duration_modin, filter_play_duration_polars),\n",
    "    ('Data Summarization - Avg', avg_pandas, avg_fireducks, avg_modin, avg_polars),\n",
    "]\n",
    "\n",
    "pd_df = load_pandas(path1)\n",
    "fd_df = load_fireducks(path1)\n",
    "# Benchmark Pandas\n",
    "for operation_name, op_pandas, op_fireducks, op_modin, op_polars in operations:\n",
    "    time_operation(pd_df, op_pandas, 'Pandas', operation_name)\n",
    "\n",
    "# Benchmark FireDucks\n",
    "for operation_name, op_pandas, op_fireducks, op_modin, op_polars in operations:\n",
    "    time_operation(fd_df, op_fireducks, 'FireDucks', operation_name)\n",
    "\n",
    "# # Benchmark Modin\n",
    "# for operation_name, op_pandas, op_fireducks, op_modin, op_polars in operations:\n",
    "#     time_operation(load_modin, op_modin, 'Modin', operation_name)\n",
    "\n",
    "# # Benchmark Polars\n",
    "# for operation_name, op_pandas, op_fireducks, op_modin, op_polars in operations:\n",
    "#     time_operation(load_polars, op_polars, 'Polars', operation_name)\n",
    "\n",
    "# Create DataFrame from results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to CSV file\n",
    "output_path = f\"./results\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "results_df.to_csv(f'{output_path}/benchmark_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49215ae4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:02:19.965062Z",
     "iopub.status.busy": "2024-08-04T01:02:19.964181Z",
     "iopub.status.idle": "2024-08-04T01:02:23.884681Z",
     "shell.execute_reply": "2024-08-04T01:02:23.883418Z",
     "shell.execute_reply.started": "2024-08-04T01:02:19.965009Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot results for each operation\n",
    "operations = results_df['Operation'].unique()\n",
    "libraries = results_df['Library'].unique()\n",
    "colors = ['blue', 'orange', 'green', 'red']\n",
    "\n",
    "# Combined plot for all operations\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "bar_width = 0.2\n",
    "index = np.arange(len(operations))\n",
    "\n",
    "for i, lib in enumerate(libraries):\n",
    "    times = []\n",
    "    for op in operations:\n",
    "        time = results_df[(results_df['Library'] == lib) & (results_df['Operation'] == op)]['Time (seconds)'].values[0]\n",
    "        times.append(time)\n",
    "    ax.bar(index + i * bar_width, times, bar_width, label=lib, color=colors[i])\n",
    "\n",
    "ax.set_xlabel('Operation')\n",
    "ax.set_ylabel('Time (seconds)')\n",
    "ax.set_title('Execution Time by Operation and Library')\n",
    "ax.set_xticks(index + bar_width * (len(libraries) - 1) / 2)\n",
    "ax.set_xticklabels(operations, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "# Add annotations for time\n",
    "for i, op in enumerate(operations):\n",
    "    for j, lib in enumerate(libraries):\n",
    "        lib_time = results_df[(results_df['Library'] == lib) & (results_df['Operation'] == op)]['Time (seconds)'].values[0]\n",
    "        ax.text(index[i] + j * bar_width, lib_time, f\"{lib_time:.2f} s\", ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_path}/execution_times.png')\n",
    "plt.show()\n",
    "\n",
    "# Separate plots for each operation\n",
    "for op in operations:\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(libraries))\n",
    "    for i, lib in enumerate(libraries):\n",
    "        time = results_df[(results_df['Library'] == lib) & (results_df['Operation'] == op)]['Time (seconds)'].values[0]\n",
    "        ax.bar(index[i], time, bar_width, label=lib, color=colors[i])\n",
    "        ax.text(index[i], time, f\"{time:.2f} s\", ha='center', va='bottom')\n",
    "    \n",
    "    ax.set_xlabel('Library')\n",
    "    ax.set_ylabel('Time (seconds)')\n",
    "    ax.set_title(f'Execution Time for {op}')\n",
    "    ax.set_xticks(index)\n",
    "    ax.set_xticklabels(libraries, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/{op}_execution_times.png')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eabed66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:02:23.886762Z",
     "iopub.status.busy": "2024-08-04T01:02:23.886345Z",
     "iopub.status.idle": "2024-08-04T01:02:25.241643Z",
     "shell.execute_reply": "2024-08-04T01:02:25.239221Z",
     "shell.execute_reply.started": "2024-08-04T01:02:23.886721Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def add_time_annotations(ax, results_df, operation, bar_width, index):\n",
    "    for i, lib in enumerate(results_df['Library'].unique()):\n",
    "        lib_time = results_df[(results_df['Library'] == lib) & (results_df['Operation'] == operation)]['Time (seconds)'].values[0]\n",
    "        ax.text(index[i] + bar_width / 2, lib_time, f\"{lib_time:.2f} s\", ha='center', va='bottom')\n",
    "\n",
    "# Plot results for each operation\n",
    "operations = results_df['Operation'].unique()\n",
    "libraries = results_df['Library'].unique()\n",
    "colors = ['blue', 'orange', 'green']\n",
    "\n",
    "# Combined plot for all operations\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "bar_width = 0.09\n",
    "index = np.arange(len(operations))\n",
    "\n",
    "for i, lib in enumerate(libraries):\n",
    "    times = []\n",
    "    for op in operations:\n",
    "        time = results_df[(results_df['Library'] == lib) & (results_df['Operation'] == op)]['Time (seconds)'].values[0]\n",
    "        times.append(time)\n",
    "    ax.bar(index + i * bar_width, times, bar_width, label=lib, color=colors[i-1])\n",
    "\n",
    "ax.set_xlabel('Operation')\n",
    "ax.set_ylabel('Time (seconds)')\n",
    "ax.set_title('Execution Time by Operation and Library')\n",
    "ax.set_xticks(index + bar_width * (len(libraries) - 1) / 2)\n",
    "ax.set_xticklabels(operations, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "# Add annotations for time\n",
    "for op in operations:\n",
    "    add_time_annotations(ax, results_df, op, bar_width, index)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_path}/execution_times.png')\n",
    "plt.show()\n",
    "\n",
    "# Separate plots for each operation\n",
    "for op in operations:\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(libraries))\n",
    "    for i, lib in enumerate(libraries):\n",
    "        time = results_df[(results_df['Library'] == lib) & (results_df['Operation'] == op)]['Time (seconds)'].values[0]\n",
    "        ax.bar(index[i], time, bar_width, label=lib, color=colors[i])\n",
    "    \n",
    "    ax.set_xlabel('Library')\n",
    "    ax.set_ylabel('Time (seconds)')\n",
    "    ax.set_title(f'Execution Time for {op}')\n",
    "    ax.set_xticks(index)\n",
    "    ax.set_xticklabels(libraries, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "\n",
    "    # Add annotations for time\n",
    "    add_time_annotations(ax, results_df, op, bar_width, index)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/{op}_execution_times.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b04b21",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-04T01:02:25.243540Z",
     "iopub.status.idle": "2024-08-04T01:02:25.244052Z",
     "shell.execute_reply": "2024-08-04T01:02:25.243822Z",
     "shell.execute_reply.started": "2024-08-04T01:02:25.243800Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import fireducks.pandas as fd_pd\n",
    "# import modin.pandas as md_pd\n",
    "# import polars as pl\n",
    "# import matplotlib.pyplot as plt\n",
    "# import gc\n",
    "# import logging\n",
    "# import numpy as np\n",
    "# from distributed import Client, LocalCluster\n",
    "\n",
    "# # Initialize Dask client\n",
    "# cluster = LocalCluster()\n",
    "# client = Client(cluster)\n",
    "# x\n",
    "# # Set Modin engine to Dask\n",
    "# os.environ[\"MODIN_ENGINE\"] = \"dask\"\n",
    "\n",
    "# # Configure logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# # Decorator for timing\n",
    "# def timer(func):\n",
    "#     def wrapper(*args, **kwargs):\n",
    "#         start_time = time.time()\n",
    "#         logging.info(f\"Starting {func.__name__}\")\n",
    "#         try:\n",
    "#             result = func(*args, **kwargs)\n",
    "#         except Exception as e:\n",
    "#             logging.error(f\"Error in {func.__name__}: {e}\")\n",
    "#             raise\n",
    "#         end_time = time.time()\n",
    "#         elapsed_time = end_time - start_time\n",
    "#         logging.info(f\"{func.__name__} took {elapsed_time:.4f} seconds\")\n",
    "#         return result, elapsed_time\n",
    "#     return wrapper\n",
    "\n",
    "# # Define load operations\n",
    "# @timer\n",
    "# def load_pandas(path):\n",
    "#     if path.endswith('.csv'):\n",
    "#         return pd.read_csv(path)\n",
    "#     elif path.endswith('.parquet'):\n",
    "#         return pd.read_parquet(path)\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "# @timer\n",
    "# def load_fireducks(path):\n",
    "#     if path.endswith('.csv'):\n",
    "#         return fd_pd.read_csv(path)\n",
    "#     elif path.endswith('.parquet'):\n",
    "#         return fd_pd.read_parquet(path)\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "# @timer\n",
    "# def load_modin(path):\n",
    "#     if path.endswith('.csv'):\n",
    "#         return md_pd.read_csv(path)\n",
    "#     elif path.endswith('.parquet'):\n",
    "#         return md_pd.read_parquet(path)\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "# @timer\n",
    "# def load_polars(path):\n",
    "#     if path.endswith('.csv'):\n",
    "#         return pl.read_csv(path)\n",
    "#     elif path.endswith('.parquet'):\n",
    "#         return pl.read_parquet(path)\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "# # Define clean operations\n",
    "# @timer\n",
    "# def dropna_pandas(df):\n",
    "#     return df.dropna()\n",
    "\n",
    "# @timer\n",
    "# def dropna_fireducks(df):\n",
    "#     return df.dropna()\n",
    "\n",
    "# @timer\n",
    "# def dropna_modin(df):\n",
    "#     return df.dropna()\n",
    "\n",
    "# @timer\n",
    "# def dropna_polars(df):\n",
    "#     return df.drop_nulls()\n",
    "\n",
    "# @timer\n",
    "# def filter_play_duration_pandas(df):\n",
    "#     return df[df['play_duration'] > 0]\n",
    "\n",
    "# @timer\n",
    "# def filter_play_duration_fireducks(df):\n",
    "#     return df[df['play_duration'] > 0]\n",
    "\n",
    "# @timer\n",
    "# def filter_play_duration_modin(df):\n",
    "#     return df[df['play_duration'] > 0]\n",
    "\n",
    "# @timer\n",
    "# def filter_play_duration_polars(df):\n",
    "#     return df.filter(pl.col('play_duration') > 0)\n",
    "\n",
    "# # Define data summarization operation (average of play_duration)\n",
    "# @timer\n",
    "# def avg_pandas(df):\n",
    "#     return df['play_duration'].mean()\n",
    "\n",
    "# @timer\n",
    "# def avg_fireducks(df):\n",
    "#     return df['play_duration'].mean()\n",
    "\n",
    "# @timer\n",
    "# def avg_modin(df):\n",
    "#     return df['play_duration'].mean()\n",
    "\n",
    "# @timer\n",
    "# def avg_polars(df):\n",
    "#     return df.select(pl.col('play_duration').mean())\n",
    "\n",
    "# # Define grouping operation\n",
    "# @timer\n",
    "# def groupby_trackid_count_pandas(df):\n",
    "#     return df.groupby('track_id').size()\n",
    "\n",
    "# @timer\n",
    "# def groupby_trackid_count_fireducks(df):\n",
    "#     return df.groupby('track_id').size()\n",
    "\n",
    "# @timer\n",
    "# def groupby_trackid_count_modin(df):\n",
    "#     return df.groupby('track_id').size()\n",
    "\n",
    "# @timer\n",
    "# def groupby_trackid_count_polars(df):\n",
    "#     return df.group_by('track_id').count()\n",
    "\n",
    "# # Measure and record_ results\n",
    "# results = {\n",
    "#     'Library': [],\n",
    "#     'Operation': [],\n",
    "#     'Time (seconds)': []\n",
    "# }\n",
    "\n",
    "# for lib, load_func, dropna_func, filter_func, avg_func, groupby_func in [\n",
    "#     ('Pandas', load_pandas, dropna_pandas, filter_play_duration_pandas, avg_pandas, groupby_trackid_count_pandas),\n",
    "#     ('FireDucks', load_fireducks, dropna_fireducks, filter_play_duration_fireducks, avg_fireducks, groupby_trackid_count_fireducks),\n",
    "#     ('Modin', load_modin, dropna_modin, filter_play_duration_modin, avg_modin, groupby_trackid_count_modin),\n",
    "#     ('Polars', load_polars, dropna_polars, filter_play_duration_polars, avg_polars, groupby_trackid_count_polars),\n",
    "# ]:\n",
    "#     df1, time_taken = load_func(path1)\n",
    "#     results['Library'].append(lib)\n",
    "#     results['Operation'].append('Load Interactions')\n",
    "#     results['Time (seconds)'].append(time_taken)\n",
    "    \n",
    "#     df2, time_taken = dropna_func(df1)\n",
    "#     results['Library'].append(lib)\n",
    "#     results['Operation'].append('Clean Interactions - Drop NA')\n",
    "#     results['Time (seconds)'].append(time_taken)\n",
    "#     del df2\n",
    "    \n",
    "#     df3, time_taken = filter_func(df1)\n",
    "#     results['Library'].append(lib)\n",
    "#     results['Operation'].append('Clean Interactions - Filter Play Duration')\n",
    "#     results['Time (seconds)'].append(time_taken)\n",
    "#     del df3\n",
    "    \n",
    "#     df4, time_taken = avg_func(df1)\n",
    "#     results['Library'].append(lib)\n",
    "#     results['Operation'].append('Data Summarization - Avg')\n",
    "#     results['Time (seconds)'].append(time_taken)\n",
    "#     del df4\n",
    "\n",
    "#     # Free memory\n",
    "#     del df1\n",
    "   \n",
    "#     gc.collect()\n",
    "\n",
    "# # Create DataFrame from results\n",
    "# results_df = pd.DataFrame(results)\n",
    "\n",
    "# # Save results to CSV file\n",
    "# output_path = f\"/kaggle/working/results\"\n",
    "# os.makedirs(output_path, exist_ok=True)\n",
    "# results_df.to_csv(f'{output_path}/benchmark_results.csv', index=False)\n",
    "\n",
    "# # def add_speedup_annotations(ax, results_df, operation):\n",
    "# #     fireducks_time = results_df[(results_df['Library'] == 'FireDucks') & (results_df['Operation'] == operation)]['Time (seconds)'].values[0]\n",
    "# #     for lib in results_df['Library'].unique():\n",
    "# #         if lib != 'FireDucks':\n",
    "# #             lib_time = results_df[(results_df['Library'] == lib) & (results_df['Operation'] == operation)]['Time (seconds)'].values[0]\n",
    "# #             speedup = lib_time / fireducks_time\n",
    "# #             ax.text(index + i * bar_width, lib_time, f\"{speedup:.2f}x slower\", ha='center', va='bottom')\n",
    "\n",
    "# # # Plot results for each operation\n",
    "# # operations = results_df['Operation'].unique()\n",
    "# # libraries = results_df['Library'].unique()\n",
    "# # colors = ['blue', 'orange', 'green', 'red']\n",
    "\n",
    "# # fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # bar_width = 0.15\n",
    "# # index = np.arange(len(operations))\n",
    "\n",
    "# # for i, lib in enumerate(libraries):\n",
    "# #     times = []\n",
    "# #     for op in operations:\n",
    "# #         time = results_df[(results_df['Library'] == lib) & (results_df['Operation'] == op)]['Time (seconds)'].values[0]\n",
    "# #         times.append(time)\n",
    "# #     ax.bar(index + i * bar_width, times, bar_width, label=lib, color=colors[i])\n",
    "\n",
    "# # ax.set_xlabel('Operation')\n",
    "# # ax.set_ylabel('Time (seconds)')\n",
    "# # ax.set_title('Execution Time by Operation and Library')\n",
    "# # ax.set_xticks(index + bar_width * (len(libraries) - 1) / 2)\n",
    "# # ax.set_xticklabels(operations, rotation=45, ha='right')\n",
    "# # ax.legend()\n",
    "\n",
    "# # # Add annotations for speedup\n",
    "# # for op in operations:\n",
    "# #     add_speedup_annotations(ax, results_df, op)\n",
    "\n",
    "# # plt.tight_layout()\n",
    "# # plt.savefig('/kaggle/working/results/execution_times.png')\n",
    "# # plt.show()\n",
    "\n",
    "# # # Final memory cleanup\n",
    "# # gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af41fc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-04T01:02:25.246303Z",
     "iopub.status.idle": "2024-08-04T01:02:25.246808Z",
     "shell.execute_reply": "2024-08-04T01:02:25.246598Z",
     "shell.execute_reply.started": "2024-08-04T01:02:25.246576Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a14c037",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-04T01:02:25.248874Z",
     "iopub.status.idle": "2024-08-04T01:02:25.249440Z",
     "shell.execute_reply": "2024-08-04T01:02:25.249188Z",
     "shell.execute_reply.started": "2024-08-04T01:02:25.249166Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcff6f7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-04T01:02:25.252637Z",
     "iopub.status.idle": "2024-08-04T01:02:25.253340Z",
     "shell.execute_reply": "2024-08-04T01:02:25.252993Z",
     "shell.execute_reply.started": "2024-08-04T01:02:25.252964Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import fireducks.pandas as fd_pd\n",
    "# import modin.pandas as md_pd\n",
    "# import polars as pl\n",
    "# import matplotlib.pyplot as plt\n",
    "# import gc\n",
    "# import logging\n",
    "# import numpy as np\n",
    "# from distributed import Client, LocalCluster\n",
    "\n",
    "# # Initialize Dask client\n",
    "# cluster = LocalCluster()\n",
    "# client = Client(cluster)\n",
    "\n",
    "# # Set Modin engine to Dask\n",
    "# os.environ[\"MODIN_ENGINE\"] = \"dask\"\n",
    "\n",
    "# # Configure logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# # File paths\n",
    "# path1 = \"/kaggle/input/zvuk-dataset/zvuk-interactions.parquet\"  # Update to .csv if needed\n",
    "# path2 = \"/kaggle/input/zvuk-dataset/zvuk-track_artist_embedding.parquet\"  # Update to .csv if needed\n",
    "\n",
    "\n",
    "# # Decorator for timing\n",
    "# def timer(func):\n",
    "#     def wrapper(*args, **kwargs):\n",
    "#         start_time = time.time()\n",
    "#         logging.info(f\"Starting {func.__name__}\")\n",
    "#         try:\n",
    "#             result = func(*args, **kwargs)\n",
    "#         except Exception as e:\n",
    "#             logging.error(f\"Error in {func.__name__}: {e}\")\n",
    "#             raise\n",
    "#         end_time = time.time()\n",
    "#         elapsed_time = end_time - start_time\n",
    "#         logging.info(f\"{func.__name__} took {elapsed_time:.4f} seconds\")\n",
    "#         return result, elapsed_time\n",
    "#     return wrapper\n",
    "\n",
    "# # Define load and reduce operations\n",
    "# @timer\n",
    "# def load_reduce_pandas(path, fraction):\n",
    "#     if path.endswith('.csv'):\n",
    "#         df = pd.read_csv(path)\n",
    "#     elif path.endswith('.parquet'):\n",
    "#         df = pd.read_parquet(path)\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported file format\")\n",
    "#     return df.sample(frac=fraction, random_state=1)\n",
    "\n",
    "# @timer\n",
    "# def load_reduce_fireducks(path, fraction):\n",
    "#     if path.endswith('.csv'):\n",
    "#         df = fd_pd.read_csv(path)\n",
    "#     elif path.endswith('.parquet'):\n",
    "#         df = fd_pd.read_parquet(path)\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported file format\")\n",
    "#     return df.sample(frac=fraction, random_state=1)\n",
    "\n",
    "# @timer\n",
    "# def load_reduce_modin(path, fraction):\n",
    "#     if path.endswith('.csv'):\n",
    "#         df = md_pd.read_csv(path)\n",
    "#     elif path.endswith('.parquet'):\n",
    "#         df = md_pd.read_parquet(path)\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported file format\")\n",
    "#     return df.sample(frac=fraction, random_state=1)\n",
    "\n",
    "# @timer\n",
    "# def load_reduce_polars(path, fraction):\n",
    "#     if path.endswith('.csv'):\n",
    "#         df = pl.read_csv(path)\n",
    "#     elif path.endswith('.parquet'):\n",
    "#         df = pl.read_parquet(path)\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported file format\")\n",
    "#     return df.sample(fraction)\n",
    "\n",
    "# # Define clean operations\n",
    "# @timer\n",
    "# def dropna_pandas(df):\n",
    "#     return df.dropna()\n",
    "\n",
    "# @timer\n",
    "# def dropna_fireducks(df):\n",
    "#     return df.dropna()\n",
    "\n",
    "# @timer\n",
    "# def dropna_modin(df):\n",
    "#     return df.dropna()\n",
    "\n",
    "# @timer\n",
    "# def dropna_polars(df):\n",
    "#     return df.drop_nulls()\n",
    "\n",
    "# @timer\n",
    "# def filter_play_duration_pandas(df):\n",
    "#     return df[df['play_duration'] > 0]\n",
    "\n",
    "# @timer\n",
    "# def filter_play_duration_fireducks(df):\n",
    "#     return df[df['play_duration'] > 0]\n",
    "\n",
    "# @timer\n",
    "# def filter_play_duration_modin(df):\n",
    "#     return df[df['play_duration'] > 0]\n",
    "\n",
    "# @timer\n",
    "# def filter_play_duration_polars(df):\n",
    "#     return df.filter(pl.col('play_duration') > 0)\n",
    "\n",
    "# # Define data summarization operation (average of play_duration)\n",
    "# @timer\n",
    "# def avg_pandas(df):\n",
    "#     return df['play_duration'].mean()\n",
    "\n",
    "# @timer\n",
    "# def avg_fireducks(df):\n",
    "#     return df['play_duration'].mean()\n",
    "\n",
    "# @timer\n",
    "# def avg_modin(df):\n",
    "#     return df['play_duration'].mean()\n",
    "\n",
    "# @timer\n",
    "# def avg_polars(df):\n",
    "#     return df.select(pl.col('play_duration').mean())\n",
    "\n",
    "# # Define grouping operation\n",
    "# @timer\n",
    "# def groupby_trackid_count_pandas(df):\n",
    "#     return df.groupby('track_id').size()\n",
    "\n",
    "# @timer\n",
    "# def groupby_trackid_count_fireducks(df):\n",
    "#     return df.groupby('track_id').size()\n",
    "\n",
    "# @timer\n",
    "# def groupby_trackid_count_modin(df):\n",
    "#     return df.groupby('track_id').size()\n",
    "\n",
    "# @timer\n",
    "# def groupby_trackid_count_polars(df):\n",
    "#     return df.group_by('track_id').count()\n",
    "\n",
    "# # Define join operation\n",
    "# @timer\n",
    "# def join_pandas(df1, df2):\n",
    "#     return df1.merge(df2, on='track_id', how='inner')\n",
    "\n",
    "# @timer\n",
    "# def join_fireducks(df1, df2):\n",
    "#     return fd_pd.merge(df1, df2, on='track_id', how='inner')\n",
    "\n",
    "# @timer\n",
    "# def join_modin(df1, df2):\n",
    "#     return md_pd.merge(df1, df2, on='track_id', how='inner')\n",
    "\n",
    "# @timer\n",
    "# def join_polars(df1, df2):\n",
    "#     return df1.join(df2, on='track_id', how='inner')\n",
    "\n",
    "# # Measure and record results\n",
    "# results2 = {\n",
    "#     'Library': [],\n",
    "#     'Operation': [],\n",
    "#     'Time (seconds)': []\n",
    "# }\n",
    "\n",
    "# fraction = 0.5 \n",
    "# for lib, load_func, join_func, dropna_func, filter_func, avg_func, groupby_func in [\n",
    "#     ('Pandas', load_reduce_pandas, join_pandas, dropna_pandas, filter_play_duration_pandas, avg_pandas, groupby_trackid_count_pandas),\n",
    "#     ('FireDucks', load_reduce_fireducks, join_fireducks, dropna_fireducks, filter_play_duration_fireducks, avg_fireducks, groupby_trackid_count_fireducks),\n",
    "#     ('Modin', load_reduce_modin, join_modin, dropna_modin, filter_play_duration_modin, avg_modin, groupby_trackid_count_modin),\n",
    "#     ('Polars', load_reduce_polars, join_polars, dropna_polars, filter_play_duration_polars, avg_polars, groupby_trackid_count_polars),\n",
    "# ]:\n",
    "#     df1, time_taken = load_func(path1, fraction)\n",
    "#     df2, _ = load_func(path2, fraction)\n",
    "\n",
    "    \n",
    "#     df5, time_taken = groupby_func(df1)\n",
    "#     results2['Library'].append(lib)\n",
    "#     results2['Operation'].append('Grouping by track_id - Count')\n",
    "#     results2['Time (seconds)'].append(time_taken)\n",
    "\n",
    "#     del df5\n",
    "    \n",
    "#     df_joined, time_taken = join_func(df1, df2)\n",
    "#     results2['Library'].append(lib)\n",
    "#     results2['Operation'].append('Join Data')\n",
    "#     results2['Time (seconds)'].append(time_taken)\n",
    "    \n",
    "#     del df_joined\n",
    "#     # Free memory\n",
    "#     del df1\n",
    "#     del df2\n",
    "   \n",
    "#     gc.collect()\n",
    "\n",
    "# # Create DataFrame from results\n",
    "# results_df2 = pd.DataFrame(results2)\n",
    "\n",
    "# # Save results to CSV file\n",
    "# output_path = f\"/kaggle/working/results\"\n",
    "# os.makedirs(output_path, exist_ok=True)\n",
    "# results_df2.to_csv(f'{output_path}/benchmark_results2.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce5c1d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-04T01:02:25.257879Z",
     "iopub.status.idle": "2024-08-04T01:02:25.258602Z",
     "shell.execute_reply": "2024-08-04T01:02:25.258260Z",
     "shell.execute_reply.started": "2024-08-04T01:02:25.258229Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def add_speedup_annotations(ax, results_df, operation, bar_width, index):\n",
    "#     fireducks_time = results_df[(results_df['Library'] == 'FireDucks') & (results_df['Operation'] == operation)]['Time (seconds)'].values[0]\n",
    "#     for i, lib in enumerate(results_df['Library'].unique()):\n",
    "#         if lib != 'FireDucks':\n",
    "#             lib_time = results_df[(results_df['Library'] == lib) & (results_df['Operation'] == operation)]['Time (seconds)'].values[0]\n",
    "#             speedup = lib_time / fireducks_time\n",
    "#             ax.text(index[i] + bar_width / 2, lib_time, f\"{speedup:.2f}x slower\", ha='center', va='bottom')\n",
    "\n",
    "# results_df = results_df2\n",
    "# # Plot results for each operation\n",
    "# operations = results_df['Operation'].unique()\n",
    "# libraries = results_df['Library'].unique()\n",
    "# colors = ['blue', 'orange', 'green', 'red']\n",
    "\n",
    "# # Combined plot for all operations\n",
    "# fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# bar_width = 0.09\n",
    "# index = np.arange(len(operations))\n",
    "\n",
    "# for i, lib in enumerate(libraries):\n",
    "#     times = []\n",
    "#     for op in operations:\n",
    "#         time = results_df[(results_df['Library'] == lib) & (results_df['Operation'] == op)]['Time (seconds)'].values[0]\n",
    "#         times.append(time)\n",
    "#     ax.bar(index + i * bar_width, times, bar_width, label=lib, color=colors[i])\n",
    "\n",
    "# ax.set_xlabel('Operation')\n",
    "# ax.set_ylabel('Time (seconds)')\n",
    "# ax.set_title('Execution Time by Operation and Library')\n",
    "# ax.set_xticks(index + bar_width * (len(libraries) - 1) / 2)\n",
    "# ax.set_xticklabels(operations, rotation=45, ha='right')\n",
    "# ax.legend()\n",
    "\n",
    "# # # Add annotations for speedup\n",
    "# # for op in operations:\n",
    "# #     add_speedup_annotations(ax, results_df, op, bar_width, index + bar_width * (len(libraries) - 1) / 2)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'{output_path}/execution_times.png')\n",
    "# plt.show()\n",
    "\n",
    "# # Separate plots for each operation\n",
    "# for op in operations:\n",
    "#     fig, ax = plt.subplots(figsize=(12, 8))\n",
    "#     bar_width = 0.35\n",
    "#     index = np.arange(len(libraries))\n",
    "#     for i, lib in enumerate(libraries):\n",
    "#         time = results_df[(results_df['Library'] == lib) & (results_df['Operation'] == op)]['Time (seconds)'].values[0]\n",
    "#         ax.bar(index[i], time, bar_width, label=lib, color=colors[i])\n",
    "    \n",
    "#     ax.set_xlabel('Library')\n",
    "#     ax.set_ylabel('Time (seconds)')\n",
    "#     ax.set_title(f'Execution Time for {op}')\n",
    "#     ax.set_xticks(index)\n",
    "#     ax.set_xticklabels(libraries, rotation=45, ha='right')\n",
    "#     ax.legend()\n",
    "\n",
    "#     # Add annotations for speedup\n",
    "#     add_speedup_annotations(ax, results_df, op, bar_width, index)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f'{output_path}/{op}_execution_times.png')\n",
    "#     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291ef19f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-04T01:02:25.260718Z",
     "iopub.status.idle": "2024-08-04T01:02:25.261409Z",
     "shell.execute_reply": "2024-08-04T01:02:25.261080Z",
     "shell.execute_reply.started": "2024-08-04T01:02:25.261052Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del results_df\n",
    "# del results_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b109a16b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5162654,
     "sourceId": 8623693,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35.810399,
   "end_time": "2024-08-05T04:48:29.138650",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-05T04:47:53.328251",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
